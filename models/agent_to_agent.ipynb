{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import collections\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Custom Classes\n",
    "from prep import Preparation\n",
    "from gru_decoder import GRU_Decoder\n",
    "from gru_encoder import GRU_Encoder\n",
    "from cnn_encoder import CNN_Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_model = tf.keras.applications.ResNet50(include_top=False, weights='imagenet')\n",
    "image_input = image_model.input\n",
    "hidden_layer = image_model.layers[-1].output\n",
    "image_features_extract_model = tf.keras.Model(image_input, hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load labels\n",
    "with open(\"../dataset/captions.json\", \"r\") as jf:\n",
    "    data = json.loads(jf.read())\n",
    "data.pop(\"lstm_labels\")\n",
    "image_paths = list(data.keys())\n",
    "random.shuffle(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_name_vector = []\n",
    "for i in range(len(image_paths)):\n",
    "    img_name_vector.append(f\"../dataset/prep_data/{image_paths[i]}.jpg\")\n",
    "print(len(img_name_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test set heuristic\n",
    "STRONG_WORDS = [\"bald.\", \"bangs.\", \"big lips.\", \"big nose.\", \"black\", \"blond\", \"brown\", \"chubby.\",\n",
    "             \"double chin.\", \"eyeglasses.\", \"goatee.\", \"gray\", \"\", \"mustache.\", \"beard.\", \"oval face.\",\n",
    "             \"pale skin.\", \"pointy nose.\", \"receding hairline.\", \"rosy cheeks.\", \"sideburns.\", \"smiling.\",\n",
    "             \"straight\", \"wavy\", \"wearing earings.\", \"wearing a hat.\", \"wearing lipstick.\", \"wearing a necklace.\",\n",
    "              \"wearing a necktie.\", \"younger.\", \"older.\", \"hair\", \"He\", \"She\", \"she\", \"he\"]\n",
    "\n",
    "def heuristic(s1, s2):\n",
    "    \"\"\"\n",
    "        :s1: List of strings for the target image\n",
    "        :s2: List of strings for the distractor image\n",
    "        :return: Closeness value\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    \n",
    "    for t_sent in s1:\n",
    "        if t_sent in s2:\n",
    "            score += 1\n",
    "\n",
    "    return score / len(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset do not train on images with everything in common\n",
    "record = {} #Keeps a record of pairs id1 - id2 and id2 - id1\n",
    "target_paths = list()\n",
    "distractor_paths = list()\n",
    "\n",
    "for _ in range(2200):\n",
    "    random_numbers = []\n",
    "    image_base = image_paths[0]\n",
    "\n",
    "    while len(random_numbers) < 10:\n",
    "        num = random.randint(1, len(image_paths)-1)\n",
    "\n",
    "        image_pot = image_paths[num]\n",
    "\n",
    "        score = heuristic(data[image_base], data[image_pot])\n",
    "\n",
    "        in_record = (image_base in record and record[image_base] == image_pot) or (image_pot in record and record[image_pot] == image_base)\n",
    "\n",
    "        if (num not in random_numbers) and (score < 1) and (not in_record):\n",
    "            random_numbers.append(num)\n",
    "    \n",
    "    for k in random_numbers:\n",
    "        image_distractor = image_paths[k]\n",
    "        \n",
    "        record[image_base] = image_distractor\n",
    "        record[image_distractor] = image_base\n",
    "\n",
    "        target_paths.append(image_base)\n",
    "        distractor_paths.append(image_distractor)\n",
    "\n",
    "    random.shuffle(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Length targets: {len(target_paths)}\")\n",
    "print(f\"Length distractors: {len(distractor_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Split into train, val, and test set.\n",
    "val_slice_index = int(len(target_paths)*0.8)\n",
    "test_slice_index = int(len(target_paths)*0.9)\n",
    "\n",
    "targ_name_train, targ_name_val, targ_name_test = target_paths[:val_slice_index], target_paths[val_slice_index:test_slice_index], target_paths[test_slice_index:]\n",
    "\n",
    "dis_name_train, dis_name_val, dis_name_test = distractor_paths[:val_slice_index], distractor_paths[val_slice_index:test_slice_index], distractor_paths[test_slice_index:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(targ_name_test[0], dis_name_test[0])\n",
    "print(f\"Target Train {len(targ_name_train)}\")\n",
    "print(f\"Distractor Train {len(dis_name_train)}\")\n",
    "print(f\"Target Validation {len(targ_name_val)}\")\n",
    "print(f\"Distractor Validation {len(dis_name_val)}\")\n",
    "print(f\"Target Test {len(targ_name_test)}\")\n",
    "print(f\"Distractor Test {len(dis_name_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "img_A = mpimg.imread(f\"../dataset/prep_data/{targ_name_test[0]}.jpg\")\n",
    "img_B = mpimg.imread(f\"../dataset/prep_data/{dis_name_test[0]}.jpg\")\n",
    "\n",
    "# display images\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(img_A)\n",
    "ax[1].imshow(img_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 1000\n",
    "embedding_dims_speaker = 1024\n",
    "embedding_dims_listener = 512\n",
    "units = 512\n",
    "vocab_size = 100\n",
    "message_length = 10\n",
    "num_steps = len(targ_name_train) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = Preparation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = tf.data.Dataset.from_tensor_slices((targ_name_train, dis_name_train))\n",
    "training_data = training_data.map(lambda t, d: tf.numpy_function(prep.map_func, [t, d], [tf.float32, tf.float32]))\n",
    "training_data = training_data.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker = GRU_Decoder(embedding_dims_speaker, units, vocab_size)\n",
    "listener = GRU_Encoder(embedding_dims_listener, units, vocab_size)\n",
    "encoder_s = CNN_Encoder(embedding_dims_speaker)\n",
    "encoder_l = CNN_Encoder(embedding_dims_listener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_l = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer_s = tf.keras.optimizers.Adam(learning_rate=0.0007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpointsa2a/train\"\n",
    "ckpt = tf.train.Checkpoint(speaker = speaker,\n",
    "                           listener = listener,\n",
    "                           encoder_s = encoder_s,\n",
    "                           encoder_l = encoder_l,\n",
    "                           optimizer_l = optimizer_l,\n",
    "                           optimizer_s = optimizer_s)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "ckpt.restore(ckpt_manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot_s = []\n",
    "loss_plot_l = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(u, targ, dist):\n",
    "    loss_s = 0\n",
    "    loss_l = 0\n",
    "\n",
    "    hidden_s = speaker.reset_state(batch_size=targ.shape[0])\n",
    "    hidden_l = listener.reset_state(batch_size=targ.shape[0])\n",
    "\n",
    "    decoder_input = tf.expand_dims([1]*targ.shape[0],1,)\n",
    "    m = decoder_input\n",
    "\n",
    "    with tf.GradientTape() as tape_speaker:\n",
    "        #Encode the image through CNN\n",
    "        features = encoder_s(u)\n",
    "\n",
    "        for i in range(1, 10):\n",
    "            predictions, hidden, _ = speaker(decoder_input, features, hidden_s)\n",
    "\n",
    "            pred_probs = tf.nn.softmax(predictions)\n",
    "            log_probs = tf.math.log(pred_probs)\n",
    "\n",
    "            with tape_speaker.stop_recording():\n",
    "                col_indices = tf.cast(tf.random.categorical(predictions, 1, seed=42), tf.int32)\n",
    "                row_indices = tf.reshape(tf.range(targ.shape[0]),(targ.shape[0],1))\n",
    "                full_indices = tf.concat([row_indices,col_indices],axis=1)\n",
    "\n",
    "                entropy = tf.math.multiply(pred_probs, log_probs)\n",
    "                entropy = tf.gather_nd(entropy, full_indices)\n",
    "                entropy = tf.reshape(entropy, (32,1))\n",
    "            \n",
    "            loss_ = tf.gather_nd(log_probs, full_indices) - entropy\n",
    "          \n",
    "            loss_s += loss_\n",
    "            m = tf.concat([m, col_indices], 1)\n",
    "            decoder_input = tf.expand_dims(m[:,i], 1)\n",
    "            \n",
    "\n",
    "        with tape_speaker.stop_recording():\n",
    "            m = tf.one_hot(m, vocab_size)\n",
    "\n",
    "            with tf.GradientTape() as tape_listener:\n",
    "\n",
    "                features_t = encoder_l(targ)\n",
    "                features_d = encoder_l(dist)\n",
    "\n",
    "                #Compute loss for listener\n",
    "                v = listener(m, hidden_l)\n",
    "\n",
    "                with tape_listener.stop_recording():\n",
    "                    rand_n = random.random()\n",
    "\n",
    "                    if rand_n > 0.5:\n",
    "                        left = features_t\n",
    "                        right = features_d\n",
    "                        y_t = tf.convert_to_tensor([[1,0]]*targ.shape[0],dtype=tf.float32)\n",
    "                    else:\n",
    "                        left = features_d\n",
    "                        right = features_t\n",
    "                        y_t = tf.convert_to_tensor([[0,1]]*targ.shape[0],dtype=tf.float32)\n",
    "            \n",
    "                x = tf.norm(tf.keras.layers.dot([left, v],axes=2,normalize=True),axis=(1,2))\n",
    "                y = tf.norm(tf.keras.layers.dot([right, v],axes=2,normalize=True),axis=(1,2))\n",
    "                x = tf.reshape(x, (x.shape[0],1))\n",
    "                y = tf.reshape(y, (y.shape[0],1))\n",
    "                z = tf.concat([x,y],axis=1)\n",
    "                y_p = tf.nn.softmax(z)\n",
    "                loss_l = loss_object(y_t, y_p)\n",
    "\n",
    "                with tape_listener.stop_recording():\n",
    "                    #rewards compute\n",
    "                    mask = tf.math.greater(x, y)\n",
    "                    rewards = tf.where(mask, 1, -1)\n",
    "\n",
    "        rewards = tf.cast(rewards, tf.float32)\n",
    "        loss_s = tf.math.multiply(loss_s, rewards)\n",
    "        loss_s = -tf.reduce_mean(loss_s)\n",
    "\n",
    "    trainable_vars_s = encoder_s.trainable_variables + speaker.trainable_variables\n",
    "    # trainable_vars_s = speaker.trainable_variables\n",
    "    #Gradient (speaker)\n",
    "    gradients_s = tape_speaker.gradient(loss_s, trainable_vars_s)\n",
    "    #Optimizer (speaker)\n",
    "    optimizer_s.apply_gradients(zip(gradients_s, trainable_vars_s))\n",
    "\n",
    "    #Trainable variables for encoder + decoder (listener)\n",
    "    trainable_vars_l = encoder_l.trainable_variables + listener.trainable_variables\n",
    "    #Gradient (listener)\n",
    "    gradients_l = tape_listener.gradient(loss_l, trainable_vars_l)\n",
    "    #Optimizer (listener)\n",
    "    optimizer_l.apply_gradients(zip(gradients_l, trainable_vars_l))\n",
    "\n",
    "    return loss_s, loss_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = tf.data.Dataset.from_tensor_slices((targ_name_val, dis_name_val))\n",
    "val_data = val_data.map(lambda t, d: tf.numpy_function(prep.map_func, [t, d], [tf.float32, tf.float32]))\n",
    "val_data = val_data.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data):\n",
    "    total_right = 0\n",
    "    total_wrong = 0\n",
    "\n",
    "    for (batch, (targ_tensor, dis_tensor)) in enumerate(data):\n",
    "        hidden_s = speaker.reset_state(batch_size=targ_tensor.shape[0])\n",
    "        hidden_l = listener.reset_state(batch_size=targ_tensor.shape[0])\n",
    "\n",
    "        decoder_input = tf.expand_dims([1]*targ_tensor.shape[0],1)\n",
    "        m = decoder_input\n",
    "\n",
    "        u = tf.concat([targ_tensor, dis_tensor], -1)\n",
    "\n",
    "        #Encode the image through CNN\n",
    "        features = encoder_s(u)\n",
    "\n",
    "        #make sure that these are 256+256 = 512 and not 32+32 = 64\n",
    "        for i in range(1,10):\n",
    "            predictions, hidden, _ = speaker(decoder_input, features, hidden_s)\n",
    "            \n",
    "            preds = tf.nn.softmax(predictions)\n",
    "            indices = tf.math.argmax(predictions, axis=1)\n",
    "            indices = tf.reshape(tf.cast(indices, tf.int32),(targ_tensor.shape[0],1))\n",
    "            \n",
    "            m = tf.concat([m, indices],1)\n",
    "\n",
    "            decoder_input = indices\n",
    "\n",
    "        m = tf.one_hot(m, vocab_size)\n",
    "\n",
    "        features_t = encoder_l(targ_tensor)\n",
    "        features_d = encoder_l(dis_tensor)\n",
    "\n",
    "        rand_n = random.random()\n",
    "\n",
    "        if rand_n > 0.5:\n",
    "            left = features_t\n",
    "            right = features_d\n",
    "        else:\n",
    "            left = features_d\n",
    "            right = features_t\n",
    "\n",
    "        v = listener(m, hidden_l)\n",
    "\n",
    "        x = tf.norm(tf.keras.layers.dot([left, v],axes=2,normalize=True),axis=(1,2))\n",
    "        y = tf.norm(tf.keras.layers.dot([right, v],axes=2,normalize=True),axis=(1,2))\n",
    "\n",
    "        mask = tf.math.greater(x, y)\n",
    "        total_right += np.sum(mask.numpy())\n",
    "        total_wrong += np.sum(mask.numpy()==False)\n",
    "\n",
    "    total = total_right + total_wrong\n",
    "\n",
    "    acc = total_right / total\n",
    "\n",
    "    return acc, total_right, total_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "for epoch in range(7, EPOCHS):\n",
    "    start = time.time()\n",
    "    total_loss_s = 0\n",
    "    total_loss_l = 0\n",
    "\n",
    "    for (batch, (targ_tensor, dis_tensor)) in enumerate(training_data):\n",
    "      u = tf.concat([targ_tensor, dis_tensor], -1)\n",
    "\n",
    "      s_loss, l_loss = train_step(u, targ_tensor, dis_tensor)\n",
    "      total_loss_s += s_loss\n",
    "      total_loss_l += l_loss\n",
    "\n",
    "      if batch % 100 == 0:\n",
    "          print ('Epoch {} Batch {} Speaker Loss {:.4f} Listener Loss {:.4f}'.format(\n",
    "            epoch + 1, batch, s_loss.numpy(), l_loss.numpy()))\n",
    "\n",
    "          # acc, tot_right, tot_wrong = evaluate(val_data)\n",
    "          # tot = tot_right + tot_wrong\n",
    "          # print(f'Epoch {epoch+1} Batch {batch} Accuracy of Validation Set {acc} for {tot} samples')\n",
    "\n",
    "    # storing the epoch end loss value to plot later\n",
    "    loss_plot_s.append(total_loss_s / num_steps)\n",
    "    loss_plot_l.append(total_loss_l / num_steps)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "      ckpt_manager.save()\n",
    "\n",
    "    print ('Epoch {} Speaker Loss {:.6f} Listener Loss {:.6f}'.format(epoch + 1,\n",
    "                                         total_loss_s/num_steps, total_loss_l/num_steps))\n",
    "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = tf.data.Dataset.from_tensor_slices((targ_name_test, dis_name_test))\n",
    "test_data = test_data.map(lambda t, d: tf.numpy_function(prep.map_func, [t, d], [tf.float32, tf.float32]))\n",
    "test_data = test_data.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(-1 * loss_plot_s, color='r', label='Speaker loss')\n",
    "plt.plot(loss_plot_l, color='b', label='Listener loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Emergent communication loss plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_func_test(img_name, img_name_2):\n",
    "  img_tensor = np.load('../dataset/prep_data/'+img_name.decode('utf-8')+'.jpg.npy')\n",
    "  img_tensor_2 = np.load('../dataset/prep_data/'+img_name_2.decode('utf-8')+'.jpg.npy')\n",
    "\n",
    "  return img_tensor, img_tensor_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../dataset/best_captions.json\", \"r\") as jfec:\n",
    "    data = json.loads(jfec.read())\n",
    "\n",
    "target_data = data['target_paths']\n",
    "distractor_data = data['distractor_paths']\n",
    "\n",
    "val_slice_index = int(len(target_data)*0.8)\n",
    "test_slice_index = int(len(target_data)*0.9)\n",
    "\n",
    "targ_test = target_data[test_slice_index:]\n",
    "\n",
    "dis_test = distractor_data[test_slice_index:]\n",
    "\n",
    "testset = tf.data.Dataset.from_tensor_slices((targ_test, dis_test))\n",
    "testset = testset.map(lambda item1, item2: tf.numpy_function(\n",
    "          map_func_test, [item1, item2], [tf.float32, tf.float32]))\n",
    "\n",
    "testset = testset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "with open(\"../dataset/easy_captions.json\", \"r\") as jfec:\n",
    "    easy_data = json.loads(jfec.read())\n",
    "\n",
    "target_easy_data = easy_data['target_paths']\n",
    "distractor_easy_data = easy_data['distractor_paths']\n",
    "\n",
    "val_slice_index = int(len(target_easy_data)*0.8)\n",
    "test_slice_index = int(len(target_easy_data)*0.9)\n",
    "\n",
    "targ_easy_test = target_easy_data[test_slice_index:]\n",
    "\n",
    "dis_easy_test = distractor_easy_data[test_slice_index:]\n",
    "\n",
    "testset_easy = tf.data.Dataset.from_tensor_slices((targ_easy_test, dis_easy_test))\n",
    "testset_easy = testset_easy.map(lambda item1, item2: tf.numpy_function(\n",
    "          map_func_test, [item1, item2], [tf.float32, tf.float32]))\n",
    "\n",
    "testset_easy = testset_easy.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_understanding(data):\n",
    "    total_right = 0\n",
    "    total_wrong = 0\n",
    "\n",
    "    for (batch, (targ_tensor, dis_tensor)) in enumerate(data):\n",
    "        hidden_s = speaker.reset_state(batch_size=targ_tensor.shape[0])\n",
    "        hidden_l = listener.reset_state(batch_size=targ_tensor.shape[0])\n",
    "\n",
    "        dec_input = tf.expand_dims([1] * targ_tensor.shape[0], 1)\n",
    "\n",
    "        m = dec_input\n",
    "\n",
    "        u = tf.concat([targ_tensor, dis_tensor], -1)\n",
    "\n",
    "        #Encode the image through CNN\n",
    "        features = encoder_s(u)\n",
    "\n",
    "        #make sure that these are 256+256 = 512 and not 32+32 = 64\n",
    "        for i in range(1,vocab_size):\n",
    "            predictions, hidden, _ = speaker(dec_input, features, hidden_s)\n",
    "            \n",
    "            preds = tf.nn.softmax(predictions)\n",
    "            indices = tf.math.argmax(predictions, axis=1)\n",
    "            indices = tf.reshape(tf.cast(indices, tf.int32),(targ_tensor.shape[0],1))\n",
    "            \n",
    "            m = tf.concat([m, indices],1)\n",
    "\n",
    "            dec_input = indices\n",
    "\n",
    "        m = tf.one_hot(m, vocab_size)\n",
    "\n",
    "        features_t = encoder_l(targ_tensor)\n",
    "        features_d = encoder_l(dis_tensor)\n",
    "\n",
    "        rand_n = random.random()\n",
    "\n",
    "        left = features_t\n",
    "        right = features_d\n",
    "\n",
    "        v = listener(m, hidden_l)\n",
    "\n",
    "        x = tf.norm(tf.keras.layers.dot([left, v],axes=2,normalize=True),axis=(1,2))\n",
    "        y = tf.norm(tf.keras.layers.dot([right, v],axes=2,normalize=True),axis=(1,2))\n",
    "\n",
    "        mask = tf.math.greater(x, y)\n",
    "        total_right += np.sum(mask.numpy())\n",
    "        total_wrong += np.sum(mask.numpy()==False)\n",
    "\n",
    "    total = total_right + total_wrong\n",
    "\n",
    "    acc = total_right / total\n",
    "\n",
    "    return acc, total_right, total_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
