{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import collections\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Custom Classes\n",
    "from prep import Preparation\n",
    "from gru_encoder import GRU_Encoder\n",
    "from cnn_encoder import CNN_Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_model = tf.keras.applications.ResNet50(include_top=False, weights='imagenet')\n",
    "image_input = image_model.input\n",
    "hidden_layer = image_model.layers[-1].output\n",
    "image_features_extract_model = tf.keras.Model(image_input, hidden_layer)\n",
    "\n",
    "prep = Preparation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7faa18016810>"
     },
     "metadata": {},
     "execution_count": 118
    }
   ],
   "source": [
    "#Import the pre-trained listener (Works with 97%+ Accuracy)\n",
    "gru_encoder = GRU_Encoder(512, 512, 46)\n",
    "encoder = CNN_Encoder(512)\n",
    "optimizer_l = tf.keras.optimizers.Adam()\n",
    "loss_object_l = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "loss_plot_l = []\n",
    "\n",
    "#Load Pre-Trained Listener Model\n",
    "l_checkpoint_path = \"./checkpointslistener/train\"\n",
    "l_ckpt = tf.train.Checkpoint(encoder=encoder,\n",
    "                             gru_encoder=gru_encoder,\n",
    "                             optimizer_l=optimizer_l)\n",
    "l_ckpt_manager = tf.train.CheckpointManager(l_ckpt, l_checkpoint_path, max_to_keep=30)\n",
    "l_ckpt.restore(l_ckpt_manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## RANDOM ##\n",
    "#Import all the captions\n",
    "with open(\"../dataset/captions.json\", 'r') as jf:\n",
    "    data_all = json.loads(jf.read())\n",
    "data_all.pop('lstm_labels')\n",
    "img_paths = list(data_all.keys())\n",
    "\n",
    "edited_captions = []\n",
    "\n",
    "for img_path in img_paths:\n",
    "    captions = data_all[img_path]\n",
    "    for c in captions:\n",
    "        ed = f'<start> {c} <end>'\n",
    "        edited_captions.append(ed)\n",
    "\n",
    "#Tokenize\n",
    "top_v = 45\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=top_v,\n",
    "                                                  oov_token=\"<unk>\",\n",
    "                                                  filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ')\n",
    "tokenizer.fit_on_texts(edited_captions)\n",
    "tokenizer.word_index['<pad>'] = 0\n",
    "tokenizer.index_word[0] = '<pad>'\n",
    "\n",
    "# Create the tokenized vectors\n",
    "train_seqs = tokenizer.texts_to_sequences(edited_captions)\n",
    "\n",
    "cap_vector = tf.keras.preprocessing.sequence.pad_sequences(train_seqs, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_func_test(img_name, img_name_2):\n",
    "  img_tensor = np.load('../dataset/prep_data/'+img_name.decode('utf-8')+'.jpg.npy')\n",
    "  img_tensor_2 = np.load('../dataset/prep_data/'+img_name_2.decode('utf-8')+'.jpg.npy')\n",
    "  uno = int(img_name)\n",
    "\n",
    "  return img_tensor, img_tensor_2, uno\n",
    "\n",
    "def map_func_disc(img_name, img_name_2, cap):\n",
    "  img_tensor = np.load('../dataset/prep_data/'+img_name.decode('utf-8')+'.jpg.npy')\n",
    "  img_tensor_2 = np.load('../dataset/prep_data/'+img_name_2.decode('utf-8')+'.jpg.npy')\n",
    "\n",
    "  return img_tensor, img_tensor_2, cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 1000\n",
    "vocab_size = top_v + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BEST CAPT ##\n",
    "\n",
    "with open(\"../dataset/best_captions.json\", \"r\") as jfec:\n",
    "    data = json.loads(jfec.read())\n",
    "\n",
    "target_data = data['target_paths']\n",
    "distractor_data = data['distractor_paths']\n",
    "captions_data = data['best_captions']\n",
    "edited_captions_data = []\n",
    "\n",
    "for c in captions_data:\n",
    "    edited_captions_data.append('<start> {c} <end>')\n",
    "\n",
    "test_slice_index = int(len(target_data)*0.9)\n",
    "\n",
    "targ_test = target_data[test_slice_index:]\n",
    "dis_test = distractor_data[test_slice_index:]\n",
    "cap_test = edited_captions_data[test_slice_index:]\n",
    "\n",
    "train_seqs_2 = tokenizer.texts_to_sequences(cap_test)\n",
    "cap_vector = tf.keras.preprocessing.sequence.pad_sequences(train_seqs_2, padding='post')\n",
    "\n",
    "testset = tf.data.Dataset.from_tensor_slices((targ_test, dis_test, cap_vector))\n",
    "testset = testset.map(lambda item1, item2, item3: tf.numpy_function(\n",
    "          map_func_disc, [item1, item2, item3], [tf.float32, tf.float32, tf.int32]))\n",
    "\n",
    "testset = testset.shuffle(BUFFER_SIZE).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../dataset/best_captions.json\", \"r\") as jfec:\n",
    "    data = json.loads(jfec.read())\n",
    "\n",
    "target_data = data['target_paths']\n",
    "distractor_data = data['distractor_paths']\n",
    "\n",
    "val_slice_index = int(len(target_data)*0.8)\n",
    "test_slice_index = int(len(target_data)*0.9)\n",
    "\n",
    "targ_test = target_data[test_slice_index:]\n",
    "\n",
    "dis_test = distractor_data[test_slice_index:]\n",
    "\n",
    "testset = tf.data.Dataset.from_tensor_slices((targ_test, dis_test))\n",
    "testset = testset.map(lambda item1, item2: tf.numpy_function(\n",
    "          map_func_test, [item1, item2], [tf.float32, tf.float32, tf.int64]))\n",
    "\n",
    "testset = testset.shuffle(BUFFER_SIZE).batch(1)\n",
    "\n",
    "with open(\"../dataset/easy_captions.json\", \"r\") as jfec:\n",
    "    easy_data = json.loads(jfec.read())\n",
    "\n",
    "target_easy_data = easy_data['target_paths']\n",
    "distractor_easy_data = easy_data['distractor_paths']\n",
    "\n",
    "val_slice_index = int(len(target_easy_data)*0.8)\n",
    "test_slice_index = int(len(target_easy_data)*0.9)\n",
    "\n",
    "targ_easy_test = target_easy_data[test_slice_index:]\n",
    "\n",
    "dis_easy_test = distractor_easy_data[test_slice_index:]\n",
    "\n",
    "testset_easy = tf.data.Dataset.from_tensor_slices((targ_easy_test, dis_easy_test))\n",
    "testset_easy = testset_easy.map(lambda item1, item2: tf.numpy_function(\n",
    "          map_func_test, [item1, item2], [tf.float32, tf.float32, tf.int64]))\n",
    "\n",
    "testset_easy = testset_easy.shuffle(BUFFER_SIZE).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_understanding_random(data):\n",
    "    total_right = 0\n",
    "    total_wrong = 0\n",
    "\n",
    "    for (batch, (targ_tensor, dis_tensor, targ_name)) in enumerate(data):\n",
    "        hidden_l = gru_encoder.reset_state(batch_size=targ_tensor.shape[0])\n",
    "\n",
    "        #Find a random caption associated with the target\n",
    "        targ_name = targ_name.numpy()[0]\n",
    "        captions = data_all[str(targ_name)]\n",
    "        seed = random.randint(0, len(captions)-1)\n",
    "        caption = f\"<start> {captions[seed]} <end>\"\n",
    "        m = tokenizer.texts_to_sequences([caption])\n",
    "        m = tf.one_hot(m, vocab_size)\n",
    "\n",
    "        features_t = encoder_l(targ_tensor)\n",
    "        features_d = encoder_l(dis_tensor)\n",
    "\n",
    "        left = features_t\n",
    "        right = features_d\n",
    "\n",
    "        v = gru_encoder(m, hidden_l)\n",
    "\n",
    "        x = tf.norm(tf.keras.layers.dot([left, v],axes=2,normalize=True),axis=(1,2))\n",
    "        y = tf.norm(tf.keras.layers.dot([right, v],axes=2,normalize=True),axis=(1,2))\n",
    "\n",
    "        mask = tf.math.greater(x, y)\n",
    "        total_right += np.sum(mask.numpy())\n",
    "        total_wrong += np.sum(mask.numpy()==False)\n",
    "\n",
    "    total = total_right + total_wrong\n",
    "\n",
    "    acc = total_right / total\n",
    "\n",
    "    return acc, total_right, total_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_understanding_disc(data):\n",
    "    total_right = 0\n",
    "    total_wrong = 0\n",
    "\n",
    "    for (batch, (targ_tensor, dis_tensor, cap)) in enumerate(data):\n",
    "        hidden_l = gru_encoder.reset_state(batch_size=targ_tensor.shape[0])\n",
    "\n",
    "        m = tf.one_hot(cap, vocab_size)\n",
    "\n",
    "        features_t = encoder(targ_tensor)\n",
    "        features_d = encoder(dis_tensor)\n",
    "\n",
    "        left = features_t\n",
    "        right = features_d\n",
    "\n",
    "        v = gru_encoder(m, hidden_l)\n",
    "\n",
    "        x = tf.norm(tf.keras.layers.dot([left, v],axes=2,normalize=True),axis=(1,2))\n",
    "        y = tf.norm(tf.keras.layers.dot([right, v],axes=2,normalize=True),axis=(1,2))\n",
    "\n",
    "        mask = tf.math.greater(x, y)\n",
    "        total_right += np.sum(mask.numpy())\n",
    "        total_wrong += np.sum(mask.numpy()==False)\n",
    "\n",
    "    total = total_right + total_wrong\n",
    "\n",
    "    acc = total_right / total\n",
    "\n",
    "    return acc, total_right, total_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 100/100 [01:08<00:00,  1.47it/s]\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "## HUMAN EVALUATION RANDOM ##\n",
    "with open('../human_evaluation/x.json', 'r') as jf:\n",
    "    X = json.loads(jf.read())\n",
    "\n",
    "def show_test_random(num, save):\n",
    "    captions = data_all[str(target_data[num])]\n",
    "    rand = random.randint(0, len(captions)-1)\n",
    "    phrase = f\"Utterance: {captions[rand]}\"\n",
    "    img_A = mpimg.imread(f\"../dataset/prep_data/{target_data[num]}.jpg\")\n",
    "    img_B = mpimg.imread(f\"../dataset/prep_data/{distractor_data[num]}.jpg\")\n",
    "\n",
    "    rand_n = random.uniform(0,1)\n",
    "\n",
    "    if rand_n < 0.5:\n",
    "        t = 0\n",
    "        d = 1\n",
    "    else:\n",
    "        t = 1\n",
    "        d = 0\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    ax[t].imshow(img_A)\n",
    "    ax[d].imshow(img_B)\n",
    "    fig.suptitle(phrase)\n",
    "    plt.savefig(f'../human_evaluation/random/{save}.png')\n",
    "    plt.clf()\n",
    "    return t\n",
    "\n",
    "correct = {}\n",
    "for i in tqdm(range(len(X))):\n",
    "    curr_ind = X[i]\n",
    "    t = show_test_random(curr_ind, i)\n",
    "    correct[i] = t\n",
    "\n",
    "with open(\"../human_evaluation/random/correct.json\", \"w\") as wj:\n",
    "    json.dump(correct, wj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "## HUMAN EVALUATION BEST CAPTION ##\n",
    "with open('../human_evaluation/x.json', 'r') as jf:\n",
    "    X = json.loads(jf.read())\n",
    "\n",
    "def show_test_discriminative(num, save):\n",
    "    phrase = f\"Utterance: {captions_data[num]}\"\n",
    "    img_A = mpimg.imread(f\"../dataset/prep_data/{target_data[num]}.jpg\")\n",
    "    img_B = mpimg.imread(f\"../dataset/prep_data/{distractor_data[num]}.jpg\")\n",
    "\n",
    "    rand_n = random.uniform(0,1)\n",
    "\n",
    "    if rand_n < 0.5:\n",
    "        t = 0\n",
    "        d = 1\n",
    "    else:\n",
    "        t = 1\n",
    "        d = 0\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    ax[t].imshow(img_A)\n",
    "    ax[d].imshow(img_B)\n",
    "    fig.suptitle(phrase)\n",
    "    plt.savefig(f'../human_evaluation/discriminative/{save}.png')\n",
    "    plt.clf()\n",
    "    return t\n",
    "\n",
    "correct = {}\n",
    "for i in tqdm(range(len(X))):\n",
    "    curr_ind = X[i]\n",
    "    t = show_test_discriminative(curr_ind, i)\n",
    "    correct[i] = t\n",
    "\n",
    "with open(\"../human_evaluation/discriminative/correct.json\", \"w\") as wj:\n",
    "    json.dump(correct, wj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HUMAN EVALUATION BEST CAPTION ##\n",
    "with open('../human_evaluation/x.json', 'r') as jf:\n",
    "    X = json.loads(jf.read())\n",
    "\n",
    "def show_test_report(num, save):\n",
    "    phrase = f\"Utterance: {captions_data[num]}\"\n",
    "    img_A = mpimg.imread(f\"../dataset/prep_data/{target_data[num]}.jpg\")\n",
    "    img_B = mpimg.imread(f\"../dataset/prep_data/{distractor_data[num]}.jpg\")\n",
    "\n",
    "    rand_n = random.uniform(0,1)\n",
    "\n",
    "    # if rand_n < 0.5:\n",
    "    t = 0\n",
    "    d = 1\n",
    "    # else:\n",
    "    #     t = 1\n",
    "    #     d = 0\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    ax[t].imshow(img_A)\n",
    "    ax[t].set_title(\"Target Image\")\n",
    "    ax[t].axis('off')\n",
    "    ax[d].imshow(img_B)\n",
    "    ax[d].set_title(\"Distractor Image\")\n",
    "    ax[d].axis('off')\n",
    "    plt.rcParams['font.family'] = 'serif'\n",
    "    # fig.suptitle(phrase)\n",
    "    plt.savefig(f'../human_evaluation/base/{save}.png')\n",
    "    plt.clf()\n",
    "    return t\n",
    "\n",
    "correct = {}\n",
    "\n",
    "curr_ind = X[96]\n",
    "t = show_test_report(curr_ind, 96)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}